{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. Think about how the `REQUIRED_SKILLS` set and the `DESIRED_SKILLS` set can be used in the program. Also, why are the variables in ALL CAPS?]_\n",
    "\n",
    "- In this cell, we are reading the resume into pandas and then declaring variables called \"required skills\" and \"desired skills\"\n",
    "- The variables are in all caps because it will eliminate the waring of invalid names for a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. How is this function defined? What does it take in, how does it work, and what does it return?]_\n",
    "\n",
    "- This function helps read the file and return all of the data\n",
    "- This funtion is defined as \"resume_file_handler\", it reads all of the data and formats it so it is easy for the user to manipulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_[Replace this with your clear explanation of what happens in the cell below. What is this cell doing? Is it passing anything? Does it get anything back? What happens to `word_list`?]_\n",
    "\n",
    "- The word_list variable is reading and obtaining the text from the csv\n",
    "- When declared it is returning all of the text within the resume\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'frank',\n",
       " 'n.',\n",
       " 'stein',\n",
       " '##',\n",
       " 'education',\n",
       " '*',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'visualization',\n",
       " 'boot',\n",
       " 'camp',\n",
       " 'graduate',\n",
       " '##',\n",
       " 'experience',\n",
       " '*',\n",
       " 'creating',\n",
       " 'pivot',\n",
       " 'tables',\n",
       " 'and',\n",
       " 'vba',\n",
       " 'scripts',\n",
       " 'in',\n",
       " 'excel.',\n",
       " '*',\n",
       " 'modeling',\n",
       " 'and',\n",
       " 'forecasting',\n",
       " 'data',\n",
       " 'using',\n",
       " 'basic',\n",
       " 'statistics',\n",
       " '*',\n",
       " 'writing',\n",
       " 'python',\n",
       " 'scripts',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'from',\n",
       " 'files',\n",
       " 'and',\n",
       " 'apis.',\n",
       " '*',\n",
       " 'social',\n",
       " 'media',\n",
       " 'mining',\n",
       " 'using',\n",
       " 'python',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'mysql',\n",
       " 'and',\n",
       " 'mongodb',\n",
       " 'databases',\n",
       " '*',\n",
       " 'developing',\n",
       " 'front-end',\n",
       " 'web',\n",
       " 'visualizations',\n",
       " 'using',\n",
       " 'html,',\n",
       " 'css,',\n",
       " 'bootstrap,',\n",
       " 'd3,',\n",
       " 'and',\n",
       " 'leaflet.js',\n",
       " '*',\n",
       " 'using',\n",
       " 'the',\n",
       " 'tableau',\n",
       " 'business',\n",
       " 'intelligence',\n",
       " 'software',\n",
       " '*',\n",
       " 'performing',\n",
       " 'big',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'with',\n",
       " 'hadoop',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " '##',\n",
       " 'skills',\n",
       " '*',\n",
       " 'microsoft',\n",
       " 'excel,',\n",
       " 'python,',\n",
       " 'javascript,',\n",
       " 'html/css,',\n",
       " 'api',\n",
       " 'interactions,',\n",
       " 'social',\n",
       " 'media',\n",
       " 'mining,',\n",
       " 'sql,',\n",
       " 'hadoop,',\n",
       " 'tableau,',\n",
       " 'advanced',\n",
       " 'statistics,',\n",
       " 'machine',\n",
       " 'learning,',\n",
       " 'r,',\n",
       " 'git/github',\n",
       " '##',\n",
       " 'interests',\n",
       " '*',\n",
       " 'contributing',\n",
       " 'to',\n",
       " 'open-source',\n",
       " 'software',\n",
       " '*',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'with',\n",
       " 'python',\n",
       " 'and',\n",
       " 'pandas',\n",
       " '*',\n",
       " 'designing',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'web',\n",
       " 'apps',\n",
       " 'with',\n",
       " 'html,',\n",
       " 'css,',\n",
       " 'javascript,',\n",
       " 'and',\n",
       " 'd3',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'big',\n",
       " 'data',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cloud',\n",
       " 'using',\n",
       " 'aws']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created? -- A set is being created so the user can return a sorted sequence of unique words from the resume\n",
    "* How are we populating the set?  -- We are populating the set by utilizing tokens from the word_list we pulled in the last cell\n",
    "* Why would it be necessary to create a `punctuation` set? -- It is necessary to create a punctuation set so that we do not pull any unneccessary punctuation marks and only whole words\n",
    "* What does subtracting from the set do? -- Subtracting from the set allows the user to find the differences between each set, in this particular example we are finding the elements present in resume but not in punctuation\n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string -- \\n is a newline in a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'mining,', 'excel,', 'boot', 'with', 'experience', 'working', 'mysql', 'performing', 'scripts', 'from', 'education', 'developing', 'mining', '#', 'excel.', '*', 'web', 'python', 'hadoop,', 'open-source', 'visualizations', 'n.', 'leaflet.js', 'big', 'pivot', 'sets', 'writing', 'visualization', 'html,', 'using', 'learning', 'to', 'statistics,', 'css,', 'designing', 'interactions,', 'frank', 'algorithms', 'microsoft', 'data', 'forecasting', 'hadoop', 'in', 'media', 'software', 'r,', 'tables', 'files', 'camp', 'bootstrap,', 'modeling', 'aws', 'intelligence', 'databases', 'sql,', 'vba', 'd3,', 'skills', 'social', 'python,', '##', 'machine', 'javascript,', 'apps', 'statistics', 'contributing', 'advanced', 'creating', 'graduate', 'the', 'pandas', 'stein', 'tableau', 'api', 'front-end', 'tableau,', 'd3', 'cloud', 'business', 'basic', 'analyze', 'and', 'apis.', 'analytics', 'learning,', 'interests', 'mongodb', 'git/github', 'html/css,'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'mining,', 'excel,', 'with', 'boot', 'experience', 'working', 'mysql', 'performing', 'scripts', 'from', 'education', 'developing', 'mining', 'excel.', 'web', 'python', 'hadoop,', 'open-source', 'visualizations', 'n.', 'leaflet.js', 'big', 'pivot', 'sets', 'writing', 'visualization', 'html,', 'using', 'learning', 'to', 'statistics,', 'css,', 'designing', 'interactions,', 'frank', 'algorithms', 'microsoft', 'data', 'forecasting', 'hadoop', 'in', 'media', 'software', 'r,', 'tables', 'files', 'camp', 'bootstrap,', 'modeling', 'aws', 'intelligence', 'databases', 'sql,', 'vba', 'd3,', 'skills', 'social', 'python,', '##', 'machine', 'javascript,', 'apps', 'statistics', 'advanced', 'creating', 'graduate', 'the', 'pandas', 'stein', 'tableau', 'api', 'front-end', 'tableau,', 'd3', 'cloud', 'business', 'basic', 'analyze', 'and', 'apis.', 'git/github', 'analytics', 'learning,', 'interests', 'mongodb', 'contributing', 'html/css,'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* What does using a `set` intersection do in this section? -- A set is being used to not include words with punctuation and \"stop words\" such as \"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"\n",
    "* How does the character cleaning function work differently than the word cleaning function? (test it)  The character cleaning function is different than the word cleaning function because the word cleaning function is text specific and the user has more ability to narrow down what they want to remove\n",
    "* Can you add more items to the `stop_words` list? -- Yes you can add more words to the stop_words list\n",
    "* Explain how the list `word_list` list comprehension works. What does it return and what is the filtering criteria? -- It returns words that are not in the \"stop list\" and the filtering criteria is entirely by the user depending on what they set the stop words as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'statistics', 'mysql'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\", \"for\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* How was the `word_count` dictionary initialized, what were in initial key values, and how were they set? -- The word_count dictionary was initialized by the {}.fromkeys function\n",
    "* Explain the logic behind incrementing the world count value using the `for loop`. Be sure to explain how to reference the word key in the `word_count` dictionary -- The word count value is used through the 'for loop' by looping through the dictionary and counting each word.  This is done by the \"word_count[word] += 1\" function.\n",
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter` -- Counter is used by counting the number of objects and then creating a iterable table.  Like the for loop, it moves through this table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. Which column was sorted and how? How was the top ten selected? Does that explain the significance of `[:10]`?\n",
    "\n",
    "- The cell below utilizes a for loop to display the top 10 words used in the resume.  The experience column was the column sorted.  The top ten words were counted utilizing the for loop, the for loop is counting number of words contained in the word_count variable.\n",
    "\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
